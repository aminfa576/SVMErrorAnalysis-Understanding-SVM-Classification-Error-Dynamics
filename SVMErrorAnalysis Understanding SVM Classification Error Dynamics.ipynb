{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dacfc2f2",
   "metadata": {},
   "source": [
    "## Train a Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40bffe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f10a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.126454</td>\n",
       "      <td>1.128687</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.977622</td>\n",
       "      <td>-0.812231</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.432842</td>\n",
       "      <td>1.858138</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.068767</td>\n",
       "      <td>-0.989854</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.931646</td>\n",
       "      <td>0.544944</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2\n",
       "0  2.126454  1.128687  0.0\n",
       "1 -1.977622 -0.812231  1.0\n",
       "2  1.432842  1.858138  0.0\n",
       "3 -1.068767 -0.989854  1.0\n",
       "4  1.931646  0.544944  0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "training_data = pd.read_csv('training.csv')\n",
    "\n",
    "# Display the first few rows of the training data\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5415c",
   "metadata": {},
   "source": [
    "The training dataset consists of three columns, with the first two columns representing the input vector $ \\mathbf{x} $ and the third column representing the binary label. The input vector $ \\mathbf{x} $ belongs to the set of 2-dimensional real vectors, denoted as:\n",
    "\n",
    "$$\\mathbf{x} \\in \\mathbb{R}^2$$\n",
    "\n",
    "Now, letâ€™s proceed with training the linear SVM for values of $C$ ranging from 1 to 20:\n",
    "\n",
    "$$C = 1, 2, 3, \\ldots, 20$$\n",
    "\n",
    "For each value of $C$, we will find and store the parameters $w_C$  and $b_C$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "becd9ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'w_C': array([[-1.43341459, -1.51947951]]), 'b_C': array([-0.18720884])},\n",
       " 2: {'w_C': array([[-1.75579181, -1.85719934]]), 'b_C': array([-0.24694253])},\n",
       " 3: {'w_C': array([[-1.85670157, -1.96356676]]), 'b_C': array([-0.20370207])},\n",
       " 4: {'w_C': array([[-1.85662413, -1.9635391 ]]), 'b_C': array([-0.20368357])},\n",
       " 5: {'w_C': array([[-1.85844023, -1.9869248 ]]), 'b_C': array([-0.20575575])},\n",
       " 6: {'w_C': array([[-1.86934029, -2.10511654]]), 'b_C': array([-0.21678959])},\n",
       " 7: {'w_C': array([[-1.97501853, -2.21502526]]), 'b_C': array([-0.27080351])},\n",
       " 8: {'w_C': array([[-2.25831679, -2.33552297]]), 'b_C': array([-0.12838152])},\n",
       " 9: {'w_C': array([[-2.27173017, -2.34017221]]), 'b_C': array([-0.12021408])},\n",
       " 10: {'w_C': array([[-2.27166283, -2.34012163]]), 'b_C': array([-0.12022294])},\n",
       " 11: {'w_C': array([[-2.27165611, -2.34011658]]), 'b_C': array([-0.12022388])},\n",
       " 12: {'w_C': array([[-2.27164232, -2.34010622]]), 'b_C': array([-0.12022575])},\n",
       " 13: {'w_C': array([[-2.27163893, -2.34010367]]), 'b_C': array([-0.12022626])},\n",
       " 14: {'w_C': array([[-2.27170619, -2.34015417]]), 'b_C': array([-0.12021754])},\n",
       " 15: {'w_C': array([[-2.27166441, -2.34012279]]), 'b_C': array([-0.12022306])},\n",
       " 16: {'w_C': array([[-2.27167663, -2.34013197]]), 'b_C': array([-0.12022153])},\n",
       " 17: {'w_C': array([[-2.27165217, -2.34011359]]), 'b_C': array([-0.12022479])},\n",
       " 18: {'w_C': array([[-2.27161856, -2.34008834]]), 'b_C': array([-0.12022925])},\n",
       " 19: {'w_C': array([[-2.27171669, -2.34016204]]), 'b_C': array([-0.1202165])},\n",
       " 20: {'w_C': array([[-2.27162408, -2.34009248]]), 'b_C': array([-0.12022866])}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Extract features and labels from the training data\n",
    "X_train = training_data.iloc[:, :2].values\n",
    "y_train = training_data.iloc[:, 2].values\n",
    "\n",
    "# Initialize a dictionary to store parameters for each C\n",
    "svm_parameters = {}\n",
    "\n",
    "# Train linear SVM for C values from 1 to 20\n",
    "for C in range(1, 21):\n",
    "    # Initialize and train the SVM\n",
    "    linear_svm = SVC(kernel='linear', C=C)\n",
    "    linear_svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Extract and store the parameters w_C and b_C\n",
    "    w_C = linear_svm.coef_\n",
    "    b_C = linear_svm.intercept_\n",
    "    svm_parameters[C] = {'w_C': w_C, 'b_C': b_C}\n",
    "\n",
    "# Display the parameters for each C\n",
    "svm_parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9028d12",
   "metadata": {},
   "source": [
    "We have successfully trained linear SVM models for values of $C$ ranging from 1 to 20. The parameters $w_C$ and $b_C$ for each $C$ have been computed and stored.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2281e668",
   "metadata": {},
   "source": [
    "## Validate and Compute Error Expectation and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9557709f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.091819</td>\n",
       "      <td>0.720954</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.734850</td>\n",
       "      <td>0.360467</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.622475</td>\n",
       "      <td>2.922869</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.929786</td>\n",
       "      <td>-0.510617</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.184624</td>\n",
       "      <td>1.170605</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2\n",
       "0 -0.091819  0.720954  0.0\n",
       "1 -0.734850  0.360467  1.0\n",
       "2  1.622475  2.922869  0.0\n",
       "3 -0.929786 -0.510617  1.0\n",
       "4  1.184624  1.170605  0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the validation dataset\n",
    "validation_data = pd.read_csv('validation.csv')\n",
    "\n",
    "# Display the first few rows of the validation data\n",
    "validation_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a194b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  24,  25,  26,\n",
       "          27,  28,  29,  32,  34,  35,  36,  37,  38,  40,  41,  42,  43,\n",
       "          44,  45,  46,  47,  48,  50,  51,  52,  53,  54,  55,  56,  57,\n",
       "          58,  59,  60,  61,  62,  64,  68,  69,  70,  71,  72,  73,  74,\n",
       "          75,  76,  77,  79,  80,  81,  82,  83,  84,  85,  87,  88,  89,\n",
       "          90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
       "         103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143,\n",
       "         144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "         157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170,\n",
       "         171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n",
       "         185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 200,\n",
       "         201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
       "         214, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227,\n",
       "         228, 229, 230, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
       "         242, 243, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256,\n",
       "         257, 258, 259, 261, 262, 263, 264, 266, 267, 268, 269, 270, 271,\n",
       "         272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284,\n",
       "         285, 287, 288, 289, 290, 291, 292, 293, 295, 296, 297, 298, 299,\n",
       "         300, 301, 302, 303, 304, 305, 307, 308, 309, 310, 311, 312, 313,\n",
       "         314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 326, 328,\n",
       "         329, 330, 331, 332, 334, 335, 337, 338, 339, 340, 341, 342, 343,\n",
       "         344, 345, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 358,\n",
       "         359, 361, 362, 363, 364, 366, 367, 369, 370, 371, 372, 373, 374,\n",
       "         375, 376, 378, 379, 380, 381, 382, 384, 385, 386, 387, 388, 389,\n",
       "         390, 391, 392, 393, 394, 396, 397, 399, 400, 401, 402, 403, 404,\n",
       "         405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417,\n",
       "         418, 419, 420, 421, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
       "         433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
       "         447, 448, 449, 450, 451, 452, 453, 454, 455, 457, 458, 459, 460,\n",
       "         461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473,\n",
       "         474, 475, 476, 477, 478, 479, 480, 482, 483, 484, 485, 487, 488,\n",
       "         489, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502,\n",
       "         503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515,\n",
       "         516, 517, 518, 519, 520, 521, 522, 523, 524, 527, 528, 530, 531,\n",
       "         532, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 546, 547,\n",
       "         548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560,\n",
       "         561, 562, 563, 564, 565, 566, 567, 569, 571, 572, 573, 574, 575,\n",
       "         576, 577, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589,\n",
       "         590, 591, 592, 593, 597, 598, 599, 600, 601, 602, 603, 605, 606,\n",
       "         607, 608, 609, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620,\n",
       "         623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 636,\n",
       "         638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650,\n",
       "         651, 652, 653, 654, 656, 657, 659, 660, 661, 662, 663, 664, 665,\n",
       "         668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680,\n",
       "         681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 693, 694,\n",
       "         695, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708,\n",
       "         709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 722,\n",
       "         724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736,\n",
       "         737, 738, 739, 740, 742, 743, 744, 745, 747, 748, 749, 750, 751,\n",
       "         752, 753, 754, 755, 756, 757, 758, 759, 761, 762, 763, 764, 765,\n",
       "         766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778,\n",
       "         779, 780, 781, 782, 783, 784, 785, 786, 788, 789, 790, 791, 792,\n",
       "         793, 794, 797, 798, 799]),\n",
       "  array([ 23,  30,  31,  33,  39,  49,  63,  65,  66,  67,  78,  86, 109,\n",
       "         139, 168, 174, 192, 198, 199, 215, 231, 244, 250, 260, 265, 286,\n",
       "         294, 306, 323, 327, 333, 336, 346, 357, 360, 365, 368, 377, 383,\n",
       "         395, 398, 422, 423, 446, 456, 481, 486, 490, 525, 526, 529, 533,\n",
       "         534, 545, 568, 570, 578, 594, 595, 596, 604, 610, 621, 622, 635,\n",
       "         637, 655, 658, 666, 667, 692, 696, 721, 723, 741, 746, 760, 787,\n",
       "         795, 796])),\n",
       " (array([  0,   1,   3,   4,   5,   6,   8,   9,  11,  12,  13,  14,  15,\n",
       "          16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
       "          30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "          43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  55,  56,\n",
       "          57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "          70,  71,  73,  74,  75,  78,  79,  80,  82,  83,  85,  86,  87,\n",
       "          88,  89,  90,  91,  92,  93,  94,  95,  98,  99, 100, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117,\n",
       "         119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
       "         133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "         147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160,\n",
       "         161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
       "         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
       "         187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
       "         200, 201, 202, 203, 205, 206, 207, 212, 213, 214, 215, 216, 217,\n",
       "         219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231,\n",
       "         232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245,\n",
       "         246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259,\n",
       "         260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 272, 273,\n",
       "         274, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288,\n",
       "         289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 300, 301, 303,\n",
       "         304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 315, 317, 318,\n",
       "         319, 320, 321, 322, 323, 324, 325, 327, 328, 329, 330, 331, 332,\n",
       "         333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345,\n",
       "         346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 357, 358, 359,\n",
       "         360, 362, 363, 364, 365, 366, 368, 369, 370, 371, 372, 373, 374,\n",
       "         375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387,\n",
       "         389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "         403, 404, 405, 406, 407, 408, 410, 411, 412, 413, 414, 415, 416,\n",
       "         417, 418, 419, 420, 421, 422, 423, 424, 426, 427, 429, 430, 431,\n",
       "         433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
       "         446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
       "         459, 460, 461, 462, 463, 465, 466, 467, 468, 469, 470, 471, 472,\n",
       "         473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 484, 485, 486,\n",
       "         487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499,\n",
       "         500, 501, 502, 503, 504, 505, 507, 508, 509, 510, 511, 514, 516,\n",
       "         517, 518, 520, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,\n",
       "         533, 534, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546,\n",
       "         547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n",
       "         560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572,\n",
       "         573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585,\n",
       "         586, 587, 588, 590, 592, 593, 594, 595, 596, 597, 598, 599, 600,\n",
       "         601, 602, 603, 604, 605, 606, 607, 609, 610, 611, 612, 613, 614,\n",
       "         615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627,\n",
       "         629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 642, 643,\n",
       "         645, 646, 647, 648, 649, 650, 651, 653, 654, 655, 657, 658, 659,\n",
       "         660, 661, 663, 664, 665, 666, 667, 668, 669, 671, 672, 673, 674,\n",
       "         675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687,\n",
       "         689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
       "         702, 703, 704, 706, 707, 708, 709, 710, 711, 712, 713, 714, 716,\n",
       "         717, 718, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731,\n",
       "         732, 733, 734, 735, 736, 737, 739, 740, 741, 742, 743, 745, 746,\n",
       "         747, 748, 749, 751, 752, 753, 755, 756, 757, 759, 760, 761, 762,\n",
       "         763, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 778,\n",
       "         779, 780, 781, 782, 784, 785, 787, 788, 789, 790, 791, 792, 793,\n",
       "         794, 795, 796, 797, 799]),\n",
       "  array([  2,   7,  10,  29,  54,  72,  76,  77,  81,  84,  96,  97, 101,\n",
       "         110, 118, 120, 137, 155, 204, 208, 209, 210, 211, 218, 235, 254,\n",
       "         266, 275, 281, 296, 302, 314, 316, 326, 352, 361, 367, 388, 393,\n",
       "         409, 425, 428, 432, 464, 483, 506, 512, 513, 515, 519, 521, 532,\n",
       "         537, 589, 591, 608, 628, 640, 641, 644, 652, 656, 662, 670, 688,\n",
       "         705, 715, 719, 720, 738, 744, 750, 754, 758, 764, 776, 777, 783,\n",
       "         786, 798])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   7,   8,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "          27,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
       "          41,  42,  43,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
       "          56,  57,  58,  59,  61,  62,  63,  64,  65,  66,  67,  68,  71,\n",
       "          72,  74,  75,  76,  77,  78,  80,  81,  83,  84,  85,  86,  87,\n",
       "          88,  89,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
       "         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
       "         115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "         128, 129, 130, 134, 137, 138, 139, 141, 142, 143, 144, 146, 147,\n",
       "         149, 150, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162,\n",
       "         163, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,\n",
       "         178, 179, 180, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
       "         192, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206,\n",
       "         207, 208, 209, 210, 211, 212, 214, 215, 216, 217, 218, 219, 221,\n",
       "         222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235,\n",
       "         236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 248, 249, 250,\n",
       "         251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263,\n",
       "         265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
       "         278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291,\n",
       "         293, 294, 295, 296, 297, 298, 300, 301, 302, 303, 304, 305, 306,\n",
       "         307, 308, 310, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
       "         322, 323, 324, 325, 326, 327, 328, 330, 331, 332, 333, 334, 335,\n",
       "         336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349,\n",
       "         351, 352, 353, 354, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "         365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 378,\n",
       "         379, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 395,\n",
       "         396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408,\n",
       "         409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421,\n",
       "         422, 423, 424, 425, 426, 427, 428, 429, 430, 432, 433, 434, 435,\n",
       "         437, 438, 439, 441, 443, 445, 446, 447, 449, 451, 452, 453, 454,\n",
       "         455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "         468, 469, 470, 471, 472, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "         482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "         495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
       "         508, 509, 510, 511, 512, 513, 514, 515, 516, 518, 519, 520, 521,\n",
       "         522, 523, 524, 525, 526, 528, 529, 530, 531, 532, 533, 534, 535,\n",
       "         536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548,\n",
       "         549, 550, 551, 552, 553, 555, 556, 557, 558, 560, 561, 562, 563,\n",
       "         564, 565, 566, 567, 568, 570, 571, 572, 573, 574, 575, 577, 578,\n",
       "         579, 580, 581, 583, 584, 585, 587, 588, 589, 590, 591, 592, 593,\n",
       "         594, 595, 596, 597, 598, 599, 600, 601, 602, 604, 605, 606, 607,\n",
       "         608, 609, 610, 611, 612, 613, 614, 616, 617, 618, 619, 621, 622,\n",
       "         623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 634, 635, 636,\n",
       "         637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
       "         651, 652, 653, 654, 655, 656, 657, 658, 660, 661, 662, 663, 665,\n",
       "         666, 667, 668, 669, 670, 671, 672, 674, 675, 676, 677, 678, 679,\n",
       "         680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 692, 693, 694,\n",
       "         695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708,\n",
       "         709, 710, 711, 712, 714, 715, 716, 717, 718, 719, 720, 721, 722,\n",
       "         723, 725, 726, 727, 729, 731, 732, 733, 734, 735, 737, 738, 739,\n",
       "         740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752,\n",
       "         753, 754, 756, 757, 758, 759, 760, 762, 763, 764, 765, 766, 767,\n",
       "         768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780,\n",
       "         781, 782, 783, 784, 785, 786, 787, 788, 789, 791, 792, 793, 794,\n",
       "         795, 796, 797, 798, 799]),\n",
       "  array([  6,  28,  44,  55,  60,  69,  70,  73,  79,  82,  90, 131, 132,\n",
       "         133, 135, 136, 140, 145, 148, 158, 164, 165, 181, 193, 196, 213,\n",
       "         220, 234, 239, 247, 264, 290, 292, 299, 309, 311, 329, 342, 350,\n",
       "         355, 375, 380, 381, 382, 394, 431, 436, 440, 442, 444, 448, 450,\n",
       "         473, 517, 527, 554, 559, 569, 576, 582, 586, 603, 615, 620, 631,\n",
       "         650, 659, 664, 673, 689, 691, 707, 713, 724, 728, 730, 736, 755,\n",
       "         761, 790]))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Extract features and labels from the validation data\n",
    "X_validation = validation_data.iloc[:, :2].values\n",
    "y_validation = validation_data.iloc[:, 2].values\n",
    "\n",
    "# Define number of subsets (folds)\n",
    "num_folds = 10\n",
    "\n",
    "# Initialize KFold object with 10 folds\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Separate the validation data into 10 subsets\n",
    "folds = [(train_index, test_index) for train_index, test_index in kf.split(X_validation)]\n",
    "\n",
    "# Display the index ranges of the first few folds\n",
    "folds[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d801d9",
   "metadata": {},
   "source": [
    "We have successfully divided the validation data into 10 subsets (folds). Now, let's proceed with the computation of the expectation and variance of the classification error for each subset using the parameters $w_C$ and $b_C$ obtained from the training phase. For each value of $C$, we'll compute the classification error on each subset, then calculate the expectation and variance across the subsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f941df2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'error_expectation': 0.49309375,\n",
       "  'error_variance': 6.791894531250018e-05,\n",
       "  'error_std_dev': 0.008241295123492434},\n",
       " 2: {'error_expectation': 0.49309375,\n",
       "  'error_variance': 6.791894531250018e-05,\n",
       "  'error_std_dev': 0.008241295123492434},\n",
       " 3: {'error_expectation': 0.49381249999999993,\n",
       "  'error_variance': 4.896093750000007e-05,\n",
       "  'error_std_dev': 0.006997209265128496},\n",
       " 4: {'error_expectation': 0.49381249999999993,\n",
       "  'error_variance': 4.896093750000007e-05,\n",
       "  'error_std_dev': 0.006997209265128496},\n",
       " 5: {'error_expectation': 0.49381249999999993,\n",
       "  'error_variance': 4.896093750000007e-05,\n",
       "  'error_std_dev': 0.006997209265128496},\n",
       " 6: {'error_expectation': 0.49315625,\n",
       "  'error_variance': 6.0555664062500124e-05,\n",
       "  'error_std_dev': 0.007781751991839635},\n",
       " 7: {'error_expectation': 0.49325,\n",
       "  'error_variance': 6.164453125000016e-05,\n",
       "  'error_std_dev': 0.00785140313893002},\n",
       " 8: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973},\n",
       " 9: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973},\n",
       " 10: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973},\n",
       " 11: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973},\n",
       " 12: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973},\n",
       " 13: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973},\n",
       " 14: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973},\n",
       " 15: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973},\n",
       " 16: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973},\n",
       " 17: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973},\n",
       " 18: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973},\n",
       " 19: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973},\n",
       " 20: {'error_expectation': 0.4930312499999999,\n",
       "  'error_variance': 5.8965820312500194e-05,\n",
       "  'error_std_dev': 0.007678920517396973}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to compute classification error\n",
    "def compute_classification_error(y_true, y_pred):\n",
    "    return np.mean(y_true != y_pred)\n",
    "\n",
    "# Initialize a dictionary to store error expectation and variance for each C\n",
    "error_metrics = {}\n",
    "\n",
    "# Loop over values of C\n",
    "for C in range(1, 21):\n",
    "    # Extract parameters w_C and b_C for the current C\n",
    "    w_C = svm_parameters[C]['w_C']\n",
    "    b_C = svm_parameters[C]['b_C']\n",
    "    \n",
    "    # Initialize lists to store classification errors for each fold\n",
    "    fold_errors = []\n",
    "    \n",
    "    # Loop over subsets (folds)\n",
    "    for train_index, test_index in folds:\n",
    "        # Extract subset of validation data\n",
    "        X_fold = X_validation[test_index]\n",
    "        y_fold = y_validation[test_index]\n",
    "        \n",
    "        # Compute predictions using w_C and b_C\n",
    "        y_pred = (np.dot(X_fold, w_C.T) + b_C > 0).astype(float)\n",
    "        \n",
    "        # Compute and store classification error\n",
    "        error = compute_classification_error(y_fold, y_pred)\n",
    "        fold_errors.append(error)\n",
    "    \n",
    "    # Compute expectation and variance of classification error\n",
    "    error_expectation = np.mean(fold_errors)\n",
    "    error_variance = np.var(fold_errors)\n",
    "    error_std_dev = np.sqrt(error_variance)\n",
    "    \n",
    "    # Store error expectation and variance for the current C\n",
    "    error_metrics[C] = {\n",
    "        'error_expectation': error_expectation,\n",
    "        'error_variance': error_variance,\n",
    "        'error_std_dev': error_std_dev\n",
    "    }\n",
    "\n",
    "# Display error expectation and variance for each C\n",
    "error_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5709cd4",
   "metadata": {},
   "source": [
    "We have computed the expectation and variance of the classification error for each value of $C$, across the 10 subsets of the validation data. The expectation of the classification error and its standard deviation (the square root of the variance) for each $C$ are as follows:\n",
    "\n",
    "| $C$ | Expectation of Classification Error | Standard Deviation |\n",
    "|-----|-------------------------------------|--------------------|\n",
    "| 1   | 0.4931                              | 0.0082             |\n",
    "| 2   | 0.4931                              | 0.0082             |\n",
    "| 3   | 0.4938                              | 0.0070             |\n",
    "| 4   | 0.4938                              | 0.0070             |\n",
    "| ... | ...                                 | ...                |\n",
    "| 20  | 0.4930                              | 0.0077             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad5e9f",
   "metadata": {},
   "source": [
    "## Plot of Classification Error Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e889ca78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract values for plotting\n",
    "C_values = list(error_metrics.keys())\n",
    "error_expectations = [error_metrics[C]['error_expectation'] for C in C_values]\n",
    "error_std_devs = [error_metrics[C]['error_std_dev'] for C in C_values]\n",
    "\n",
    "# Create a plot of classification error estimate with standard deviation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(C_values, error_expectations, yerr=error_std_devs, fmt='-o', capsize=5, markersize=8)\n",
    "plt.title('Classification Error Estimate with Standard Deviation as Function of C')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Classification Error Estimate')\n",
    "plt.grid(True)\n",
    "plt.xticks(C_values)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23187b21",
   "metadata": {},
   "source": [
    "In the plot above, the classification error estimate for each value of $C$ is represented by a circle, and the standard deviation of the classification error is represented by the error bars. As you can see, the classification error estimate fluctuates slightly as $C$ varies, and the standard deviation is relatively small for all $C$.\n",
    "\n",
    "From the plot, we can observe that the classification error estimate does not vary significantly with different values of $C$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47291e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
